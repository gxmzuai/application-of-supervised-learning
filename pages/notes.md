1、

大家好，下面我来分享一下有关监督学习方法的应用方面的个人见解。

2、

今天我汇报的内容包括6个部分，第一部分，我会带大家回顾一下监督学习的概念；
二至四部分，主要介绍监督学习的两大基本问题分类和回归问题方面的应用。
第五部分，介绍监督学习在目前大火的大语言模型领域的应用。
最后做本次报告的总结。

3、

有关监督学习的要点，简要来说就是用一个带标签的数据集用于模型的训练。在训练过程中，模型学习到一个函数，这个函数用于对输入数据进行预测。一旦函数被学习完成，模型就可以被用于预测未标记的数据。 

4、

```
监督学习的最核心的两大问题是分类问题和回归问题，下面我来介绍监督学习在这两大问题方面的应用。

先来简单地介绍一下分类问题。

如幻灯片所示，分类问题的核心目标是预测离散值或类别标签。这与之后要讲的回归问题预测连续值的目标形成了鲜明的对比。

为了方便理解，我们使用动物图片分类的例子来揭示分类问题的基本流程：

1、首先，我们有一个带标签的动物图片数据集。这些图片都带有对应的动物名称标签，例如“狗”、“猫”等。

2、接着，我们使用这些带标签的图片来训练一个分类模型。这个模型将学习如何根据图片中的动物特征来识别并预测动物类别。

3、一旦模型训练完成，我们可以使用它来对那些没有标签的动物图片进行预测。模型将尝试根据它在训练过程中所学到的知识来预测图片中动物的类别。

4、最后，我们得到了模型的预测结果，即该图片所属的动物类别。
```

5、

监督学习在分类问题方面的应用有很多，以刚才流程图演示的图片分类为例。

为了方便演示，这边我们采用的是预训练的ResNet-50模型（基于ImageNet数据集的子集训练得到）来进行图片分类。

ImageNet数据集（韩枫老师在高级人工智能课上提及过）：

它是一个大型的视觉数据库。其中包含了超过1000万个手动标注的图像，涵盖了22000个不同的类别。它为机器学习模型提供了丰富的训练资料。

ResNet(Residual Network)-50模型：

它是一个卷积神经网络模型。该模型基于部分ImageNet数据集（包含1000个类别，涉及不同种类的动物、植物等）训练。被广泛应用于图像分类。

PyTorch框架提供的ResNet-50模型，是一个预先训练好的深度学习模型，能够识别图像中的对象。当我们将一张预处理过的竹叶青蛇的图片输入该模型进行识别时，模型返回了一个类别ID：59。通过查询类别对照表，我们发现这个ID对应的是“vine snake”（藤蛇）。

由于ResNet-50的训练数据集限于1000个类别，所以未能精确识别出竹叶青，但它识别出的藤蛇与竹叶青有着相似的绿色外观，这一结果仍具有参考价值。

6、

```
在这一页中，我们将探讨一个与分类问题密切相关的概念，那就是标注问题。

标注问题可以被看作是分类问题的一种扩展。与分类问题主要关注为单个输入预测一个类别标签不同，标注问题的目标是为输入数据序列中的每一个元素分配一个对应的标签。

为了方便理解，我们使用英语句子词性标注（为文本中的每个单词指定一个合适的词性）的例子来揭示标注问题的基本流程：

1、首先，我们从一个带有词性标注的英文句子数据集开始。这些句子包含了词语及其对应的词性标签，如名词、动词、形容词等。

2、接着，我们根据输入的句子及其标注来训练模型。模型将学习如何根据上下文和句子中的具体词语来预测每个词的词性。

3、训练完成后，模型可以被用来预测新的、未标注的英文句子。对于句子中的每一个词，模型都会预测其可能的词性。

4、最后，我们获得了模型对句子中每个词的词性预测结果，即为每个词提供了一个词性标签。

标注问题提供了一种更细粒度的分类方法，允许我们为输入数据的每个元素预测一个类别标签，而不仅仅是为整个输入预测一个标签。
```

7、

监督学习在标注方面的应用有很多,以刚才流程图演示的英文句子词性标注为例。

为了方便演示，我们使用的是NLTK库的预训练模型—平均感知机标注器（averaged_perceptron_tagger）来进行词性标注任务。

NLTK，全称Natural Language Toolkit，是一个功能强大且广泛应用于NLP任务的工具包。它不仅提供了平均感知机标注器，还包含了一个完善的词性标签集——Penn Treebank。

首先，我们有一个待处理的句子："The cat sat on the mat." 这个句子首先会经过文本预处理，这一步骤由nltk.word_tokenize函数完成，它将句子分割成单词和标点符号的序列，即“分词”。

完成分词后，接下来是词性标注的步骤。这是通过nltk.pos_tag函数实现的，它会对每个分词后的单元（单词和标点）分配一个词性标签。这些标签是根据Penn Treebank项目定义的标准来分配的。例如，单词"The"被标注为冠词（DT），"cat"被标注为名词（NN），"sat"被标注为过去式动词（VBD），依此类推。

通过结合使用NLTK库中的平均感知机标注器和Penn Treebank标签集，我们可以高效地对英文句子进行词性标注。这种方法不仅提高了处理速度，还保持了较高的标注准确度，展示了监督学习中的标注问题在nlp领域的实际应用价值。

8、

在这一页中，我们将探索回归问题的基本概念。

与分类问题不同，回归问题的核心目标是预测一个连续的值。这意味着，我们试图预测一个实数值，如价格、得分或其他任何连续范围内的数值。而不是预测输入数据属于哪个离散的类别

为了方便理解，我们用股票明天收盘价预测的例子来揭示回归问题的基本流程：

1. 首先，我们需要收集相关的数据，例如，我们可以使用股票在历史的今天和明天的收盘价。
2. 接着，我们使用这些历史数据来训练我们的线性回归模型。模型将学习历史数据中今天的收盘价如何影响明天的收盘价。
3. 训练完成后，我们可以输入今天的股票收盘价，模型会为我们预测明天可能的收盘价。
4. 最后，模型会输出预测的收盘价，这就是我们基于今天数据预测的明天股票收盘价。

9、

监督学习在回归问题方面的应用有很多，以刚才流程图演示的股票明天收盘价预测为例。

我们选择了一个简单的线性回归（LinearRegression）模型来进行这项任务。线性回归是最基本的回归算法之一，它旨在找到输入特征和目标输出之间的线性关系。

我们的目标是预测明天的股票收盘价。为了实现这一目标，我们将使用股票的历史数据，特别是过去的今明两天收盘价，作为我们的输入特征。

训练完线性回归模型后，提供今天该股票的收盘价，以预测明天股票的收盘价。

请注意，股票价格预测是一个复杂的问题，受到许多因素的影响。这边为了方便演示监督学习在回归问题方面的应用，简化了输入特征。

10、

去年11月底发布的ChatGPT，掀起了AI领域的大变革。

ChatGPT的模型微调过程......

在这种方法中，监督学习用于从人类反馈中学习期望的行为。

今年9月份，OpenAI新出的GPT-4V，能看，能听，能说。其中的听，使用的是OpenAI去年推出的whisper模型，其中利用到了监督学习。whisper模型使用从网络上收集到的带标注的68万小时数据进行训练。

上个月，研究生小组使用清华大学开源的ChatGLM这个大语言模型作为基础大模型，使用了包含标签和答案的数据集（train.json和dev.json）对其进行微调，这里面涉及到了监督学习。由于数据量的不足，最后微调的效果不佳。

上周OpenAI首届开发者大会后......

下图是我微调的一个GPT，用一轮对话即可实现了它身份认知的转变。当然如果追求更加完美的效果，可以附加自己独特的数据集。

通过上述内容，我们可以看到，无论是国内还是国外的研究，在大语言模型的研究中，或多或少存在监督学习的身影。

11、

做一个简短的总结。

首先，我们必须认识到，监督学习的应用是非常多样的。无论是在金融、还是其他领域，监督学习都在发挥着重要的作用。

接着我想阐明一点，虽然分类和回归是监督学习中最为基础的两大问题，但随着技术的不断进步，我们可能会看到新的应用抽象和特定的应用场景。这些新的场景可能不会完全符合我们熟悉的分类和回归框架，但它们的核心仍然是在带有标签的数据上进行模型训练。

最后，我们也看到了监督学习如何与其他机器学习分支相结合，为如今广受欢迎的大语言模型提供强大的支持。

12、

谢谢大家。 




